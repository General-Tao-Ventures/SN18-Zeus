{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# How can the Zeus Subnet be used to query miners on live data?\n",
    "\n",
    "We aim to make it as easy as possible to build a product around this subnet. By default, a validator will automatically start a Proxy process, which allows it to query miners using data of the validator's choice! This is all seamlessly integrated with the main validator logic, meaning a miner will not know whether an incoming request concerns one they will be scored on, or one that is used for a downstream product. For this proxy the current best performing miner is automatically selected, to ensure the best possible response. \n",
    "\n",
    "This notebook will briefly demonstrate how to use the Proxy API. Note that it is very simple to modify it for your own use-case, which can be done by modifying $\\texttt{zeus->api->proxy.py}$.\n",
    "By default, the API will listen for requests on port $10913$, but this can be configured in the validator.env file ($\\texttt{PROXY\\_PORT}$)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import torch\n",
    "import cartopy.crs as ccrs\n",
    "import cartopy.feature as cfeature\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Request the API\n",
    "It is of course possible to change the latitude/longitude bounding box, the number of hours the miners are shown, and the number of hours you want them to predict.\n",
    "Going outside the ranges configured for a validator is possible, but will allow miners to distinguish (and potentially filter out) a Proxy and regular (scored) request."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "200"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "request_bbox = [51, 54, 3, 7]\n",
    "\n",
    "response = requests.post(\n",
    "    url='http://localhost:10913/proxy',\n",
    "    headers={\n",
    "        'authorization': 'TODO',\n",
    "    },\n",
    "    json={\n",
    "        \"lat_start\": request_bbox[0], # coordinates of the Netherlands\n",
    "        \"lat_end\": request_bbox[1], \n",
    "        \"lon_start\": request_bbox[2],\n",
    "        \"lon_end\": request_bbox[3],\n",
    "        \"sample_hours\": 96, # how many hours of past data the miner is shown\n",
    "        \"predict_hours\": 4, # how many hours the miner should predict\n",
    "    }\n",
    ")\n",
    "response.status_code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([4, 13, 17])\n"
     ]
    }
   ],
   "source": [
    "if response.status_code == 200:\n",
    "        prediction = torch.tensor(response.json()[\"prediction\"])\n",
    "        print(prediction.shape)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venvclimate",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
